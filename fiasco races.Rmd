---
title: "Fiasco Races Round 1 - Data Analysis"
author: "Greg Sward"
date: "2022-10-19"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r data_cruncing, echo=FALSE, message=FALSE}
library(caret)
library(dplyr)
library(ggplot2)
library(ggpubr)
library(lubridate)
library(party)
library(purrr)
library(randomForest)
library(reactable)
library(rvest)
library(stringr)
library(tree)


getTimesInSeconds <- function(x){
  if(str_count(x, pattern = ":") == 1){
    return(lubridate::period_to_seconds(lubridate::ms(x)))
  }else{
    return(lubridate::period_to_seconds(lubridate::hms(x)))
  }
}


#define a function to help convert the HTML data to a useful dataframe
dataCleansing <- function(x, race_number = 0,  nrow_to_remove = 0){
  #get rid of the last 2 columns
  x <- x[,1:(ncol(x)-2)]
  
  #fix column names
  colnames(x) <- c("Cat", "Position", "Rider", "Time", "Avg_WKG", "Avg_W", "Normalized_W", "WKG_20m", "WKG_5m", "WKG_1m", "WKG_30s", "WKG_15s", "Weight", "Age", "Avg_Hr", "Max_Hr", "Height")
  
  #icons for the first 3 positions. need to fix.  A bunch of other changes, easier to do outside dplyr
  x$Position <- 1:nrow(x)
  x$Avg_WKG <- as.numeric(gsub(x = x$Avg_WKG, pattern = "w/kg", replacement = ""))
  x$Avg_W <- as.numeric(gsub(x = x$Avg_W, pattern = "w", replacement = ""))
  x$Normalized_W <- as.numeric(gsub(x = x$Normalized_W, pattern = "w", replacement = ""))
  x$WKG_20m<- as.numeric(gsub(x = x$WKG_20m, pattern = "w/kg", replacement = ""))
  x$WKG_5m<- as.numeric(gsub(x = x$WKG_5m, pattern = "w/kg", replacement = ""))
  x$WKG_1m<- as.numeric(gsub(x = x$WKG_1m, pattern = "w/kg", replacement = ""))
  x$WKG_30s<- as.numeric(gsub(x = x$WKG_30s, pattern = "w/kg", replacement = ""))
  x$WKG_15s<- as.numeric(gsub(x = x$WKG_15s, pattern = "w/kg", replacement = ""))
  x$Weight <- as.numeric(gsub(x = x$Weight, pattern = "kg", replacement = ""))
  x$Age <- as.factor(x$Age)
  x$Avg_Hr <- as.numeric(gsub(x = x$Avg_Hr, pattern = "bpm", replacement = ""))
  x$Max_Hr <- as.numeric(gsub(x = x$Max_Hr, pattern = "bpm", replacement = ""))
  x$Height <- as.numeric(gsub(x = x$Height, pattern = "cm", replacement = ""))
  
  time_chr <- map_chr(strsplit(x$Time, "\\+"), 1)
  x$Time <- map_dbl(time_chr, getTimesInSeconds)
  x$Rel_Time <- x$Time/x$Time[1]
  rm(time_chr)
  
  x <- x[1:(nrow(x)-nrow_to_remove),]
  
  #now dplyr
  x <- x %>%
    mutate(
      Round = 1,
      Race_Number = race_number,
      Top_20 = as.factor(ifelse(Position <= 20, "Yes", "No")),
      Normalized_WKG = round(Normalized_W / Weight, 2)
    ) %>%
    select(
      Round,
      Race_Number,
      Cat,
      Rider,
      Position,
      Top_20,
      Time,
      Rel_Time,
      Weight,
      Height,
      Age,
      Avg_Hr,
      Max_Hr,
      Avg_WKG,
      Avg_W,
      Normalized_WKG,
      Normalized_W,
      everything()
    ) %>%
    mutate(
      W_20m = WKG_20m * Weight,
      W_5m = WKG_5m * Weight,
      W_1m = WKG_1m * Weight,
      W_30S = WKG_30s * Weight,
      W_15s = WKG_15s * Weight
    )
  
  return(x)
}

data_files <- list(
  "ZRL_Race_1.html",
  "ZRL_Race_2.html",
  # "ZRL_Race_3.html",
  "ZRL_Race_4.html",
  "ZRL_Race_5.html")

getRaceHTMLData <- function(x){
  read_html(paste0("data/", x)) %>%
    html_element("table") %>%
    html_table()
}

race_html_data <- lapply(data_files, getRaceHTMLData)

race_data <- lapply(race_html_data, dataCleansing)
race_data <- purrr::map2_dfr(.x = race_html_data, .y = c(1,2,4,5), .f = dataCleansing) %>%
  mutate(Rider_ID = as.numeric(as.factor(Rider))) %>%
  group_by(Rider_ID) %>%
  mutate(Worst_Result = max(Position),
         Best_Result = min(Position))

```


## Data and Background

This document summarizes various data-related observations from Round 1 of Americas East Open Division 1 - C category.  The data set includes all races except Race 3 - the team time trial race.  All data was collected from Zwift Power.


## Rider Participation
Below is the distribution of number races competed in by rider.  There were `r length(unique(race_data$Rider_ID))` riders.  No rider competed in all 5 of 5 races.

``` {r group_results, echo=FALSE, message=FALSE}
d <- race_data %>%
  dplyr::select(Rider_ID) %>%
  dplyr::group_by(Rider_ID) %>%
  dplyr::summarize(Race_Count = n())

p <- ggplot(data = d, aes(x = Race_Count)) +
  geom_bar(fill = "orange") +
  theme_pubclean()

rm(d)
  
plotly::ggplotly(p)
```


## Rider Results
```{r top_20, echo = FALSE}
riders_always_top_20 <- race_data %>% 
  dplyr::select(Rider_ID, Worst_Result) %>% 
  dplyr::distinct() %>% 
  dplyr::filter(Worst_Result <= 20)

num_riders_always_top_20 <- nrow(riders_always_top_20)
```

The below Cleveland plot shows the finishing positions of different riders (the rider IDs have been anonymized).  It's interesting that almost none of the riders placed consistently in the top 10, or even top 20. The ones that tended to only do a couple races.  Many riders had a very wide range of results.  It does not appear to be uncommon for a rider to get in the top 5 in one race and 50th+ in another. Of the `r length(unique(race_data$Rider_ID))` riders, only `r num_riders_always_top_20` placed in the top 20 or better in each other their races.  *Apologies for the long plot, but there's a lot of data to display - there are interactive tools to zoom and filter by race in the top right.*

```{r rider_results, echo=FALSE, message=FALSE, fig.dim = c(12, 30)}

p <- ggdotchart(
  data = race_data %>% mutate(Race_Number = as.factor(Race_Number)),
  x = "Rider_ID",
  xlab = "Rider_ID",
  y = "Position",
  color = "Race_Number",
  #palette = c("#00AFBB", "#FC4E07"),
  sorting = "ascending",
  rotate = TRUE,                              
  dot.size = 2,
  title = "Rider ID vs Finishing Position",
  ggtheme = theme_pubr()                        
) +
  theme_cleveland()
  
plotly::ggplotly(p)

```

## Changes in Weight
Not presented here for the sake of space, but a quick check was done on the change in weight riders reported across their races.  It does not appear as though there were any suspicious 'jumps' in weight.  I had thought with the 50% rule, that some riders might lower their weights after the 3rd race to get a boost without triggering the 3.2 ceiling rule.  This does not appear to be the case.


## Rider Finishing Position Points
The finishing points for the riders was calculated and is summarized below.
```{r rider_points, echo=FALSE, message=FALSE}
getPoints <- function(position){
  if(position == 1){
    40
  }else if(position == 2){
    35
  }else if(position == 3){
    30
  }else if(position == 4){
    29
  }else if(position == 5){
    28
  }else if(position == 6){
    27
  }else if(position == 7){
    26
  }else if(position == 8){
    25
  }else if(position == 9){
    24
  }else if(position == 10){
    23
  }else if(position <= 15){
    20
  }else if(position <= 20){
    19
  }else if(position <= 25){
    18
  }else if(position <= 30){
    17
  }else if(position <= 35){
    16
  }else if(position <= 40){
    15
  }else if(position <= 45){
    14
  }else if(position <= 50){
    13
  }else if(position <= 53){
    12
  }else if(position <= 56){
    11
  }else if(position <= 59){
    10
  }else if(position <= 62){
    9
  }else if(position <= 65){
    8
  }else if(position <= 68){
    7
  }else if(position <= 71){
    6
  }else if(position <= 74){
    5
  }else if(position <= 77){
    4
  }else if(position <= 80){
    3
  }else if(position <= 83){
    2
  }else{
    1
  }
}

getPosition <- function(points){
  if(points == 40){
    1
  }else if(points == 35){
    2
  }else if(points == 30){
    3
  }else if(points == 29){
    4
  }else if(points == 28){
    5
  }else if(points == 27){
    6
  }else if(points == 26){
    7
  }else if(points == 25){
    8
  }else if(points == 24){
    9
  }else if(points == 23){
    10
  }else if(points >= 20){
    15
  }else if(points >= 19){
    20
  }else if(points >= 18){
    25
  }else if(points >= 17){
    30
  }else if(points >= 16){
    35
  }else if(points >= 15){
    40
  }else if(points >= 14){
    45
  }else if(points >= 13){
    50
  }else if(points >= 12){
    53
  }else if(points >= 11){
    56
  }else if(points >= 10){
    59
  }else if(points >= 9){
    62
  }else if(points >= 8){
    65
  }else if(points >= 7){
    68
  }else if(points >= 6){
    71
  }else if(points >= 5){
    74
  }else if(points >= 4){
    77
  }else if(points >= 3){
    80
  }else if(points >= 2){
    83
  }else{
    85
  }
}

race_data$Finish_Points <- purrr::map_dbl(race_data$Position, getPoints)

points_data <- race_data %>%
  group_by(Rider_ID) %>%
  summarise(Num_Races = n(), 
            Total_Finish_Pts = sum(Finish_Points), 
            Avg_Finish_Pts_Per_Race = round(Total_Finish_Pts/Num_Races, 2))

points_data$Equivalent_Avg_Position <- purrr::map_dbl(points_data$Avg_Finish_Pts_Per_Race, getPosition)

points_data <- points_data %>% dplyr::arrange(-Total_Finish_Pts)

reactable::reactable(
  data = points_data, 
  resizable = TRUE, 
  searchable = TRUE, 
  showPageSizeOptions = TRUE,
  showSortable = TRUE,
  striped = TRUE,
  pageSizeOptions = c(10, 50, 100, 200))
```

## Characteristics of the Top 20

```{r random_forest_1, echo=FALSE, message=FALSE}
race_model_data <- race_data %>%
  select(-Round, -Race_Number, -Cat, -Rider, -Rider_ID, -Position, -Normalized_W, 
         -Normalized_WKG, -Time, -Rel_Time, -Best_Result, -Worst_Result, -Finish_Points) %>%
  na.omit()

set.seed(100)
train <- sample(1:nrow(race_model_data), size = round(0.75*nrow(race_model_data)))
train_data <- race_model_data[train,]
test_data <- race_model_data[-train,]

rf_race <- randomForest(Top_20~., data = train_data)

#check training prediction
train_predict <- predict(rf_race,train_data)
#confusionMatrix(train_predict, train_data$Top_20)

test_predict <- predict(rf_race, test_data)

```

For each race, riders were grouped into whether or not they finished in the top 20.  A random sample of `r nrow(train_data)` results was used to train a random forest model.  Only "targetable" explanatory variables were used (i.e. Normalized W/Kg is not something a rider can directly target so it was excluded).  The model was used to predict the whether the remaining `r nrow(test_data)` results would be a top 20 finish.  The model had an overall predictive accuracy of `r confusionMatrix(test_predict, test_data$Top_20)$overall['Accuracy']`.  


```{r random_forest_2, echo=FALSE, message=FALSE}
confusionMatrix(test_predict, test_data$Top_20)

#plot(rf_race)

```


The same model approach was used to identify Top 10, Top 30, Top 40.  The model's predictive power declined from Top 10 to Top 40, which suggests that the relative difference in rider power profiles between the someone who is 15th versus 25th is more different than a rider that finishes 35th versus a rider that finishes 50th.  The Top 20 group was chosen as a 'good balance'.  The goal isn't necessarily to answer the question: "How do I get in the top 20?", rather it's "What are the metrics can I target in my training that will give me the best returns?".  The top 10 variables are shown below:


```{r random_forest_3, echo=FALSE, message=FALSE}
random_forest_variable_importance <- varImpPlot(rf_race,
           sort = T,
           n.var = 10,
           main = "Top 10 - Variable Importance")

random_forest_variable_importance
```

We can see that short-term W/Kg is carries substantially more importance than the other variables.  Taking a deeper look into the top 4 variables:



```{r random_forest_4, echo=FALSE, message=FALSE}

par(mfrow = c(2,2))
partialPlot(x = rf_race, pred.data = as.data.frame(train_data), x.var = WKG_15s, which.class = "Yes")
partialPlot(x = rf_race, pred.data = as.data.frame(train_data), x.var = WKG_30s, which.class = "Yes")
partialPlot(x = rf_race, pred.data = as.data.frame(train_data), x.var = WKG_1m, which.class = "Yes")
partialPlot(x = rf_race, pred.data = as.data.frame(train_data), x.var = Avg_WKG, which.class = "Yes")
```

It's interesting that the importance of these variables is very non-linear.  For the 30s W/Kg, it only contributes to improving your odds of getting in the top 20 if you have a value of more than 5.  

While not having the predictive power of a random forest, a simple classification tree model was run on the same data set.  The model shows that riders who have a 30s W/Kg of > 5.9 and a Avg W/Kg of > 2.6 have a slightly greater than 50% chance of finishing in the top 20.  Riders who have less than 5.9 30S W/Kg can improve their odds of finishing in the top 20 by having an Avg W/Kg of > 3.1.  This helps to give additional context to the importance of short-term power and recovery that was illustrated in the random forest model.


```{r echo=FALSE, message=FALSE}
# f <- as.formula(paste("Top_20 ~", paste(rownames(random_forest_variable_importance), collapse = " + ")))
# f2 <- as.formula("Top_20 ~ Avg_WKG + WKG_1m + WKG_30s + WKG_15s")
ctree_race <- ctree(formula = Top_20~., data = train_data)

#check training prediction
train_predict <- predict(ctree_race,train_data,type="response")
#table(train_predict,train_data$Top_20)
#mean(train_predict != train_data$Top_20) * 100

test_predict <- predict(ctree_race, test_data, type="response")
#table(test_predict,test_data$Top_20)
#mean(test_predict != test_data$Top_20) * 100
plot(ctree_race)

```




